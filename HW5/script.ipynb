{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed the `Material` and `Id` columns since the former is not numerical and the latter is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_raw = pd.read_csv('train_X.csv')\n",
    "y_raw = pd.read_csv('train_y.csv')\n",
    "\n",
    "# Drop all non-numeric features\n",
    "X = X_raw.drop(columns=['Material', 'Id'])\n",
    "y = y_raw['Egap']\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "# Spliting\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_normalized_df, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I trained a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Linear Regression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set (optional, for in-sample evaluation)\n",
    "lr_train_pred = lr_model.predict(X_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "lr_val_pred = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "lr_train_mse = mean_squared_error(y_train, lr_train_pred)\n",
    "lr_val_mse = mean_squared_error(y_val, lr_val_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE:\", lr_train_mse)\n",
    "print(\"Validation MSE:\", lr_val_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, after trying different models, I selected XGBoost, which gives the best performance in general. I also found the importance of each feature which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=7417,        # Number of boosting rounds\n",
    "    max_depth=8,             # Maximum depth of trees\n",
    "    learning_rate=0.02,       # Step size shrinkage\n",
    "    subsample=0.90,           # Fraction of samples to use per boosting round\n",
    "    colsample_bytree=0.36,    # Fraction of features to use per tree\n",
    "    reg_alpha=0.76,\n",
    "    reg_lambda=0.58,\n",
    "    min_child_weight=15,\n",
    "    random_state=5\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "X_train_inner, X_val_inner, y_train_inner, y_val_inner = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=5\n",
    ")\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val_inner, y_val_inner)], verbose=False)\n",
    "\n",
    "\n",
    "# Predict on training and validation sets\n",
    "xgb_train_pred = xgb_model.predict(X_train)\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "xgb_train_mse = mean_squared_error(y_train, xgb_train_pred)\n",
    "xgb_val_mse = mean_squared_error(y_val, xgb_val_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE:\", xgb_train_mse)\n",
    "print(\"Validation MSE:\", xgb_val_mse)\n",
    "\n",
    "# Find inportant feature\n",
    "important_features = xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used grid search to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [5000],       # Number of boosting rounds\n",
    "    'max_depth': [6, 7, 8, 9],              # Maximum depth of trees\n",
    "    'learning_rate': [0.02],   # Step size shrinkage\n",
    "    'subsample': [0.8, 0.9, 0.95],             # Fraction of samples per boosting round\n",
    "    'colsample_bytree': [0.4, 0.5, 0.6, 0.7],       # Fraction of features per tree\n",
    "    #'reg_alpha': [0.1, 0.5, 1, 5, 10],\n",
    "    #'reg_lambda': [0.1, 0.5, 1, 5, 10],\n",
    "    'min_child_weight': [5, 10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Use MSE as the scoring metric\n",
    "    cv=3,                             # 3-fold cross-validation\n",
    "    verbose=2,                        # Display progress\n",
    "    n_jobs=-1                         # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score (MSE):\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I reduced the least important features, and trained another XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Reduced\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=5000,        # Number of boosting rounds\n",
    "    max_depth=6,             # Maximum depth of trees\n",
    "    learning_rate=0.02,       # Step size shrinkage\n",
    "    subsample=0.8,           # Fraction of samples to use per boosting round\n",
    "    colsample_bytree=0.4,    # Fraction of features to use per tree\n",
    "    reg_alpha=0.76,\n",
    "    reg_lambda=0.58,\n",
    "    min_child_weight=10,\n",
    "    random_state=5\n",
    ")\n",
    "\n",
    "threshold = 0.0001\n",
    "X_train_reduced = X_train.iloc[:, important_features > threshold]\n",
    "X_val_reduced = X_val.iloc[:, important_features > threshold]\n",
    "\n",
    "# Fit the model with reduced dataset\n",
    "xgb_model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict on training and validation sets\n",
    "xgb_train_pred = xgb_model.predict(X_train_reduced)\n",
    "xgb_val_pred = xgb_model.predict(X_val_reduced)\n",
    "\n",
    "# Evaluate the model\n",
    "xgb_train_mse = mean_squared_error(y_train, xgb_train_pred)\n",
    "xgb_val_mse = mean_squared_error(y_val, xgb_val_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE:\", xgb_train_mse)\n",
    "print(\"Validation MSE:\", xgb_val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Optuna for more hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 900, 20000),\n",
    "        \"max_depth\": 8,\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.9, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 0.5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 10, 15),\n",
    "        \"random_state\": 5\n",
    "    }\n",
    "\n",
    "    # Train-test split within the training data for validation\n",
    "    X_train_inner, X_val_inner, y_train_inner, y_val_inner = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialize the XGBoost Regressor\n",
    "    model = xgb.XGBRegressor(**params, early_stopping_rounds=10, eval_metric=\"rmse\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train_inner, y_train_inner,\n",
    "        eval_set=[(X_val_inner, y_val_inner)],\n",
    "\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Predict and calculate validation MSE\n",
    "    preds = model.predict(X_val_inner)\n",
    "    mse = mean_squared_error(y_val_inner, preds)\n",
    "\n",
    "    return mse  # Optuna will minimize this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the study and optimize\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best MSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I trained the final model with all training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Reduced FINAL\n",
    "\n",
    "# Load data\n",
    "test_raw = pd.read_csv('test_X.csv')\n",
    "test = test_raw.drop(columns=['Material', 'Id'])\n",
    "scaler = StandardScaler()\n",
    "test_normalized = scaler.fit_transform(test)\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns=test.columns)\n",
    "\n",
    "# Train model\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=9000,        # Number of boosting rounds\n",
    "    max_depth=6,             # Maximum depth of trees\n",
    "    learning_rate=0.02,       # Step size shrinkage\n",
    "    subsample=0.8,           # Fraction of samples to use per boosting round\n",
    "    colsample_bytree=0.4,    # Fraction of features to use per tree\n",
    "    reg_alpha=0.76,\n",
    "    reg_lambda=0.58,\n",
    "    min_child_weight=10,\n",
    "    random_state=5\n",
    ")\n",
    "\n",
    "threshold = 0\n",
    "X_reduced = X_normalized_df.iloc[:, important_features > threshold]\n",
    "test_reduced = test_normalized_df.iloc[:, important_features > threshold]\n",
    "\n",
    "# Fit the model with reduced dataset\n",
    "xgb_model.fit(X_reduced, y)\n",
    "\n",
    "# Predict on training and validation sets\n",
    "test_pred = xgb_model.predict(test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I wrote the csv file to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make File to Submit\n",
    "\n",
    "out = pd.read_csv('y_sample_submission.csv')\n",
    "out['Egap'] = test_pred\n",
    "out.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
